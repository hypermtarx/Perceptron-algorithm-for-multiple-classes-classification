{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Perceptron algorithm for multiple classes.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofcR73r5sgyh"
      },
      "source": [
        "Perceptron algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izBYMdNosf3Q"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH9DfMCjdz__"
      },
      "source": [
        "def main():\n",
        "  print('****************************************************************************************')\n",
        "  print('The classifier accuracy for class-1 & class-2 on training dataset:\\n',test('train.data',1,2))\n",
        "  print('The classifier accuracy for class-1 & class-2 on testing dataset:\\n',test('test.data',1,2))\n",
        "  print('The classifier accuracy for class-2 & class-3 on training dataset:\\n',test('train.data',2,3))\n",
        "  print('The classifier accuracy for class-2 & class-3 on testing dataset:\\n',test('test.data',2,3))\n",
        "  print('The classifier accuracy for class-1 & class-3 on training dataset:\\n',test('train.data',1,3))\n",
        "  print('The classifier accuracy for class-1 & class-3 on testing dataset:\\n',test('test.data',1,3))\n",
        "  print('****************************************************************************************')\n",
        "  print('The accuracy of multi-class classification on training dataset:\\n',one_vs_rest('train.data'))\n",
        "  print('The accuracy of multi-class classification on testing dataset:\\n',one_vs_rest('test.data'))\n",
        "  print('****************************************************************************************')\n",
        "  print('The accuracy of multi-class classification with l2 regularisation on training dataset:')\n",
        "  print('Accurcy with regularisation coefficient 0.01 on training data:',l2_onevsrest('train.data',0.01))\n",
        "  print('Accurcy with regularisation coefficient 0.01 on testing data:',l2_onevsrest('test.data',0.01))\n",
        "  print('Accurcy with regularisation coefficient 0.1 on training data:',l2_onevsrest('train.data',0.1))\n",
        "  print('Accurcy with regularisation coefficient 0.1 on testing data:',l2_onevsrest('test.data',0.1))\n",
        "  print('Accurcy with regularisation coefficient 1.0 on training data:',l2_onevsrest('train.data',1.0))\n",
        "  print('Accurcy with regularisation coefficient 1.0 on testing data:',l2_onevsrest('test.data',1.0))\n",
        "  print('Accurcy with regularisation coefficient 10.0 on training data:',l2_onevsrest('train.data',10.0))\n",
        "  print('Accurcy with regularisation coefficient 10.0 on testing data:',l2_onevsrest('test.data',10.0))\n",
        "  print('Accurcy with regularisation coefficient 100.0 on training data:',l2_onevsrest('train.data',100.0))\n",
        "  print('Accurcy with regularisation coefficient 100.0 on testing data:',l2_onevsrest('test.data',100.0))\n",
        "  print('****************************************************************************************')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxOBbPAIi54n"
      },
      "source": [
        "main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdZ1OJfgPXla"
      },
      "source": [
        "def load_data(filename):\n",
        "  data = pd.read_csv(filename, header = None)\n",
        "  #data = data[:]\n",
        "# replace the string data class name with number\n",
        "  data = data.replace(['class-1'],1)\n",
        "  data = data.replace(['class-2'],2)\n",
        "  data = data.replace(['class-3'],3)\n",
        "# randomise the dataframe by row and keep the same order in each execution\n",
        "  data = data.sample(frac=1, random_state=42)\n",
        "# output the data as matrix\n",
        "  data = np.asmatrix(data)\n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LY-zRYi6int3"
      },
      "source": [
        "# fuction form a new dataset contains spcific classes\n",
        "# use a, b parameteres to choose the classes in the new dataset\n",
        "def separate_data(data, a, b):  \n",
        "  numRecords = len(data[:, :])\n",
        "  new_data = np.empty((0,5))\n",
        "  for index in range(numRecords):\n",
        "    if data[index, -1] == a or data[index, -1] == b:\n",
        "# in the new dataset set class-a as 1, class-b as -1\n",
        "      data[index,-1] = np.where(data[index,-1] == a, 1, -1)\n",
        "      new_data = np.vstack((new_data, data[index]))\n",
        "  return new_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsT2udzeelrn"
      },
      "source": [
        "# fuction form a new dataset that class-a as positive, other classes as negetive\n",
        "def multiclass(a):\n",
        "  data = load_data('train.data')\n",
        "  numRecords = len(data)\n",
        "  new_data = np.empty((0,5))\n",
        "  for index in range(numRecords):\n",
        "    data[index,-1] = np.where(data[index,-1] == a, 1, -1)\n",
        "    new_data = np.vstack((new_data, data[index]))\n",
        "  return new_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REThaP6tkpaf"
      },
      "source": [
        "def plot(a, b):\n",
        "  data = load_data('train.data')\n",
        "  data = separate_data(data, a, b)\n",
        "  plt.scatter(np.array(data[:40,0]), np.array(data[:40,2]), marker='o', label='class-1')\n",
        "  plt.scatter(np.array(data[40:,0]), np.array(data[40:,2]), marker='x', label='class-2')\n",
        "  plt.xlabel('petal length')\n",
        "  plt.ylabel('sepal length')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "plot(2,3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwyhtcUGsvN-"
      },
      "source": [
        "def perceptron(train_data, num_iter):\n",
        "# split actual data and class label in the dataset\n",
        "  features = train_data[:, :-1]\n",
        "  labels = train_data[:, -1]\n",
        "# set weights and bias to zero \n",
        "  w = np.zeros((1, features.shape[1]+1))\n",
        "# number of iteration \n",
        "  for iteration in range(num_iter):\n",
        "    for x, label in zip(features, labels):\n",
        "# put a 1 at the begining of each line for bias in w\n",
        "      x = np.insert(x,0,1)\n",
        "# the activation score WTX\n",
        "      activ = np.inner(w, x)\n",
        "# if the label and activation score has different sign\n",
        "      if (label * activ) <= 0:\n",
        "#perform the update rule\n",
        "        w += label * x\n",
        "  return w"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rf_8UvSIEhj"
      },
      "source": [
        "# perceptron using l2 update rule\n",
        "def l2_perceptron(train_data, num_iter, lambda_):\n",
        "  features = train_data[:, :-1]\n",
        "  labels = train_data[:, -1]\n",
        "  w = np.zeros((1, features.shape[1]+1))\n",
        "  for iteration in range(num_iter):\n",
        "    for x, label in zip(features, labels):\n",
        "      x = np.insert(x,0,1)\n",
        "      activ = np.inner(w, x)\n",
        "      if (label * activ) <= 0:\n",
        "        w = (1 - 2 * lambda_) * w + label * x\n",
        "  return w"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CvMv2w0SRAY"
      },
      "source": [
        "# output the accuracy of the binary perception between class-a & class-b\n",
        "def test(testfile, a, b):\n",
        "  data = load_data('train.data')\n",
        "  data = separate_data(data, a, b)\n",
        "  w = perceptron(data, 20)\n",
        "  correctPredictions = 0\n",
        "  #validation_data = load_data(testfile)\n",
        "  #validation_data = separate_data(validation_data, a, b)\n",
        "  features = data[:, :-1]\n",
        "  labels = data[:, -1]\n",
        "  for x, label in zip(features, labels):\n",
        "    x = np.insert(x,0,1)\n",
        "    activ = np.inner(w, x)\n",
        "    if activ * label > 0:\n",
        "      correctPredictions += 1\n",
        "  accuracy = float(correctPredictions) / float(len(data))\n",
        "  return accuracy\n",
        "#print(\"Accuracy of perceptron: \", test('test.data',1,2))   \n",
        "#print(\"Accuracy of perceptron: \", test('train.data',2,3))  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0qXPSa-d0NT"
      },
      "source": [
        "# multi-class classification using one-vs-rest then output the accuracy\n",
        "def one_vs_rest(filename):\n",
        "# form three new dataset which set the corresponding class to positive, others to negetive\n",
        "  data_1 = multiclass(1)\n",
        "  data_2 = multiclass(2)\n",
        "  data_3 = multiclass(3)\n",
        "# use perceptron algorithm to get the weight vector after 20 iterations for each set\n",
        "  w1 = perceptron(data_1, 20)\n",
        "  w2 = perceptron(data_2, 20)\n",
        "  w3 = perceptron(data_3, 20)\n",
        "  correctPredictions = 0\n",
        "# load the validation data\n",
        "  validation_data = load_data(filename)\n",
        "  features = validation_data[:, :-1]\n",
        "  labels = validation_data[:, -1]\n",
        "  for x, label in zip(features, labels):\n",
        "    x = np.insert(x,0,1)\n",
        "# three activation scores calculated using result from 3 prediction models\n",
        "    activ = np.empty((3))\n",
        "    activ[0] = np.inner(w1,x)\n",
        "    activ[1] = np.inner(w2,x)\n",
        "    activ[2]= np.inner(w3,x)\n",
        "# find the max value among three activation scores\n",
        "    activ = np.argmax(activ)\n",
        "# assign corresponding class label to the prediction\n",
        "    if activ == 0:\n",
        "      activ = 1\n",
        "    elif activ == 1:\n",
        "      activ = 2\n",
        "    else:\n",
        "      activ = 3\n",
        "# verify the prediction\n",
        "    if activ == label:\n",
        "      correctPredictions += 1\n",
        "# calculate the accuracy\n",
        "  accuracy = float(correctPredictions) / float(len(validation_data))\n",
        "  return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vmdNkQGHTay"
      },
      "source": [
        "# multi-class classifier with l2\n",
        "def l2_onevsrest(filename, lambda_):\n",
        "  data_1 = multiclass(1)\n",
        "  data_2 = multiclass(2)\n",
        "  data_3 = multiclass(3)\n",
        "  w1 = l2_perceptron(data_1, 20, lambda_)\n",
        "  w2 = l2_perceptron(data_2, 20, lambda_)\n",
        "  w3 = l2_perceptron(data_3, 20, lambda_)\n",
        "  correctPredictions = 0\n",
        "  validation_data = load_data(filename)\n",
        "  features = validation_data[:, :-1]\n",
        "  labels = validation_data[:, -1]\n",
        "  for x, label in zip(features, labels):\n",
        "    x = np.insert(x,0,1)\n",
        "    activ = np.empty((3))\n",
        "    activ[0] = np.inner(w1,x)\n",
        "    activ[1] = np.inner(w2,x)\n",
        "    activ[2] = np.inner(w3,x)\n",
        "    activ = np.argmax(activ)\n",
        "    if activ == 0:\n",
        "      activ = 1\n",
        "    elif activ == 1:\n",
        "      activ = 2\n",
        "    else:\n",
        "      activ = 3\n",
        "    if activ == label:\n",
        "      correctPredictions += 1\n",
        "  accuracy = float(correctPredictions) / float(len(validation_data))\n",
        "  return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ai-AL-JMi0Vs"
      },
      "source": [
        "\"\"\"COMP527 Data Mining and Visualisation\n",
        "Coursework 1-Perceptron algorithm\n",
        "Jining Liu-201476244\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def load_data(filename):\n",
        "    data = pd.read_csv(filename, header=None)\n",
        "    # data = data[:]\n",
        "    # replace the string data class name with number\n",
        "    data = data.replace(['class-1'], 1)\n",
        "    data = data.replace(['class-2'], 2)\n",
        "    data = data.replace(['class-3'], 3)\n",
        "    # randomise the dataframe by row and keep the same order in each execution\n",
        "    data = data.sample(frac=1, random_state=20)\n",
        "    # output the data as matrix\n",
        "    data = np.asmatrix(data)\n",
        "    return data\n",
        "\n",
        "\n",
        "# fuction form a new dataset contains spcific classes\n",
        "# use a, b parameteres to choose the classes in the new dataset\n",
        "def separate_data(data, a, b):\n",
        "    numRecords = len(data[:, :])\n",
        "    new_data = np.empty((0, 5))\n",
        "    for index in range(numRecords):\n",
        "        if data[index, -1] == a or data[index, -1] == b:\n",
        "            # in the new dataset set class-a as 1, class-b as -1\n",
        "            data[index, -1] = np.where(data[index, -1] == a, 1, -1)\n",
        "            new_data = np.vstack((new_data, data[index]))\n",
        "    return new_data\n",
        "\n",
        "\n",
        "# fuction form a new dataset that class-a as positive, other classes as negetive\n",
        "def multiclass(a):\n",
        "    data = load_data('train.data')\n",
        "    numRecords = len(data)\n",
        "    new_data = np.empty((0, 5))\n",
        "    for index in range(numRecords):\n",
        "        data[index, -1] = np.where(data[index, -1] == a, 1, -1)\n",
        "        new_data = np.vstack((new_data, data[index]))\n",
        "    return new_data\n",
        "\n",
        "\n",
        "def perceptron(train_data, num_iter):\n",
        "    # split actual data and class label in the dataset\n",
        "    features = train_data[:, :-1]\n",
        "    labels = train_data[:, -1]\n",
        "    # set weights and bias to zero\n",
        "    w = np.zeros((1, features.shape[1] + 1))\n",
        "    # number of iteration\n",
        "    for iteration in range(num_iter):\n",
        "        for x, label in zip(features, labels):\n",
        "            # put a 1 at the begining of each line for bias in w\n",
        "            x = np.insert(x, 0, 1)\n",
        "            # the activation score WTX\n",
        "            activ = np.inner(w, x)\n",
        "            # if the label and activation score has different sign\n",
        "            if (label * activ) <= 0:\n",
        "                # perform the update rule\n",
        "                w += label * x\n",
        "    return w\n",
        "\n",
        "\n",
        "# perceptron using l2 update rule\n",
        "def l2_perceptron(train_data, num_iter, lambda_):\n",
        "    features = train_data[:, :-1]\n",
        "    labels = train_data[:, -1]\n",
        "    w = np.zeros((1, features.shape[1] + 1))\n",
        "    for iteration in range(num_iter):\n",
        "        for x, label in zip(features, labels):\n",
        "            x = np.insert(x, 0, 1)\n",
        "            activ = np.inner(w, x)\n",
        "            if (label * activ) <= 0:\n",
        "                w = (1 - 2 * lambda_) * w + label * x\n",
        "    return w\n",
        "\n",
        "\n",
        "# output the accuracy of the binary perception between class-a & class-b\n",
        "def test(testfile, a, b):\n",
        "    data = load_data('train.data')\n",
        "    data = separate_data(data, a, b)\n",
        "    w = perceptron(data, 20)\n",
        "    correctPredictions = 0\n",
        "    # validation_data = load_data(testfile)\n",
        "    # validation_data = separate_data(validation_data, a, b)\n",
        "    features = data[:, :-1]\n",
        "    labels = data[:, -1]\n",
        "    for x, label in zip(features, labels):\n",
        "        x = np.insert(x, 0, 1)\n",
        "        activ = np.inner(w, x)\n",
        "        if activ * label > 0:\n",
        "            correctPredictions += 1\n",
        "    accuracy = float(correctPredictions) / float(len(data))\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "# print(\"Accuracy of perceptron: \", test('test.data',1,2))\n",
        "# print(\"Accuracy of perceptron: \", test('train.data',2,3))\n",
        "\n",
        "# multi-class classification using one-vs-rest then output the accuracy\n",
        "def one_vs_rest(filename):\n",
        "    # form three new dataset which set the corresponding class to positive, others to negetive\n",
        "    data_1 = multiclass(1)\n",
        "    data_2 = multiclass(2)\n",
        "    data_3 = multiclass(3)\n",
        "    # use perceptron algorithm to get the weight vector after 20 iterations for each set\n",
        "    w1 = perceptron(data_1, 20)\n",
        "    w2 = perceptron(data_2, 20)\n",
        "    w3 = perceptron(data_3, 20)\n",
        "    correctPredictions = 0\n",
        "    # load the validation data\n",
        "    validation_data = load_data(filename)\n",
        "    features = validation_data[:, :-1]\n",
        "    labels = validation_data[:, -1]\n",
        "    for x, label in zip(features, labels):\n",
        "        x = np.insert(x, 0, 1)\n",
        "        # three activation scores calculated using result from 3 prediction models\n",
        "        activ = np.empty((3))\n",
        "        activ[0] = np.inner(w1, x)\n",
        "        activ[1] = np.inner(w2, x)\n",
        "        activ[2] = np.inner(w3, x)\n",
        "        # find the max value among three activation scores\n",
        "        activ = np.argmax(activ)\n",
        "        # assign corresponding class label to the prediction\n",
        "        if activ == 0:\n",
        "            activ = 1\n",
        "        elif activ == 1:\n",
        "            activ = 2\n",
        "        else:\n",
        "            activ = 3\n",
        "        # verify the prediction\n",
        "        if activ == label:\n",
        "            correctPredictions += 1\n",
        "    # calculate the accuracy\n",
        "    accuracy = float(correctPredictions) / float(len(validation_data))\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "# multi-class classifier with l2\n",
        "def l2_onevsrest(filename, lambda_):\n",
        "    data_1 = multiclass(1)\n",
        "    data_2 = multiclass(2)\n",
        "    data_3 = multiclass(3)\n",
        "    w1 = l2_perceptron(data_1, 20, lambda_)\n",
        "    w2 = l2_perceptron(data_2, 20, lambda_)\n",
        "    w3 = l2_perceptron(data_3, 20, lambda_)\n",
        "    correctPredictions = 0\n",
        "    validation_data = load_data(filename)\n",
        "    features = validation_data[:, :-1]\n",
        "    labels = validation_data[:, -1]\n",
        "    for x, label in zip(features, labels):\n",
        "        x = np.insert(x, 0, 1)\n",
        "        activ = np.empty((3))\n",
        "        activ[0] = np.inner(w1, x)\n",
        "        activ[1] = np.inner(w2, x)\n",
        "        activ[2] = np.inner(w3, x)\n",
        "        activ = np.argmax(activ)\n",
        "        if activ == 0:\n",
        "            activ = 1\n",
        "        elif activ == 1:\n",
        "            activ = 2\n",
        "        else:\n",
        "            activ = 3\n",
        "        if activ == label:\n",
        "            correctPredictions += 1\n",
        "    accuracy = float(correctPredictions) / float(len(validation_data))\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "def main():\n",
        "    print('****************************************************************************************')\n",
        "    print('The classifier accuracy for class-1 & class-2 on training dataset:\\n', test('train.data', 1, 2))\n",
        "    print('The classifier accuracy for class-1 & class-2 on testing dataset:\\n', test('test.data', 1, 2))\n",
        "    print('The classifier accuracy for class-2 & class-3 on training dataset:\\n', test('train.data', 2, 3))\n",
        "    print('The classifier accuracy for class-2 & class-3 on testing dataset:\\n', test('test.data', 2, 3))\n",
        "    print('The classifier accuracy for class-1 & class-3 on training dataset:\\n', test('train.data', 1, 3))\n",
        "    print('The classifier accuracy for class-1 & class-3 on testing dataset:\\n', test('test.data', 1, 3))\n",
        "    print('****************************************************************************************')\n",
        "    print('The accuracy of multi-class classification on training dataset:\\n', one_vs_rest('train.data'))\n",
        "    print('The accuracy of multi-class classification on testing dataset:\\n', one_vs_rest('test.data'))\n",
        "    print('****************************************************************************************')\n",
        "    print('The accuracy of multi-class classification with l2 regularisation on training dataset:')\n",
        "    print('Accurcy with regularisation coefficient 0.01 on training data:', l2_onevsrest('train.data', 0.01))\n",
        "    print('Accurcy with regularisation coefficient 0.01 on testing data:', l2_onevsrest('test.data', 0.01))\n",
        "    print('Accurcy with regularisation coefficient 0.1 on training data:', l2_onevsrest('train.data', 0.1))\n",
        "    print('Accurcy with regularisation coefficient 0.1 on testing data:', l2_onevsrest('test.data', 0.1))\n",
        "    print('Accurcy with regularisation coefficient 1.0 on training data:', l2_onevsrest('train.data', 1.0))\n",
        "    print('Accurcy with regularisation coefficient 1.0 on testing data:', l2_onevsrest('test.data', 1.0))\n",
        "    print('Accurcy with regularisation coefficient 10.0 on training data:', l2_onevsrest('train.data', 10.0))\n",
        "    print('Accurcy with regularisation coefficient 10.0 on testing data:', l2_onevsrest('test.data', 10.0))\n",
        "    print('Accurcy with regularisation coefficient 100.0 on training data:', l2_onevsrest('train.data', 100.0))\n",
        "    print('Accurcy with regularisation coefficient 100.0 on testing data:', l2_onevsrest('test.data', 100.0))\n",
        "    print('****************************************************************************************')\n",
        "\n",
        "\n",
        "main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYQN2oROSm7V"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def nonlin(x, deriv = False):\n",
        "    if(deriv == True):\n",
        "        return x * (1 - x)\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "\n",
        "X = np.array([[0.35], [0.9]])\n",
        "y = np.array([[0.5]])\n",
        "\n",
        "np.random.seed(1)\n",
        "\n",
        "W0 = np.array([[0.1, 0.8], [0.4, 0.6]])\n",
        "W1 = np.array([[0.3, 0.9]])\n",
        "\n",
        "print ('original ', W0, '\\n', W1)\n",
        "\n",
        "for j in range(100):\n",
        "    l0 = X\n",
        "    l1 = nonlin(np.dot(W0, l0))\n",
        "    l2 = nonlin(np.dot(W1, l1))\n",
        "    l2_error = y - l2\n",
        "    Error = 1 / 2.0 * (y-l2)**2\n",
        "    print ('Error:', Error)\n",
        "\n",
        "    l2_delta = l2_error * nonlin(l2, deriv=True)\n",
        "\n",
        "    l1_error = l2_delta * W1 #back propagation\n",
        "    l1_delta = l1_error * nonlin(l1, deriv=True)\n",
        "\n",
        "    W1 += l2_delta * l1.T\n",
        "    W0 += l0.T.dot(l1_delta)\n",
        "    print (W0, '\\n', W1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-xjC2dN0kea"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}